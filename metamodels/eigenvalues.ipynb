{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:01:34.967881720Z",
     "start_time": "2023-08-03T13:01:34.944768419Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:02:10.389213331Z",
     "start_time": "2023-08-03T13:02:10.330642881Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "from metamodels import utils\n",
    "from tasks import gen_eigenvalues\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "x, y = gen_eigenvalues(2, 3)\n",
    "print(\"x:\", x.shape)\n",
    "print(x)\n",
    "print(\"y:\", y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:21:06.958708151Z",
     "start_time": "2023-08-03T13:21:06.763491120Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 4\n",
    "net = nn.Sequential(nn.Flatten(), utils.MLP(N**2, 16, 16, 16, out_dim=N))\n",
    "\n",
    "torchinfo.summary(net, (100, N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:27:35.149540900Z",
     "start_time": "2023-08-03T13:26:46.708301680Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.train(\n",
    "    net,\n",
    "    lambda bs: gen_eigenvalues(bs, N),\n",
    "    10_000,\n",
    "    lr=1e-4,\n",
    "    batch_size=1000,\n",
    "    log_every=100,\n",
    "    loss_fn=torch.nn.MSELoss(),\n",
    "    reuse_perfs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:53:16.294533105Z",
     "start_time": "2023-08-01T16:53:16.268630165Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.show_example(net, lambda bs: gen_eigenvalues(bs, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T17:10:11.723466884Z",
     "start_time": "2023-08-01T17:10:11.680133037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking whether eigenvalues depend on the permutation of input rows: they do\n",
    "x, y = gen_eigenvalues(1, 3)\n",
    "print(\"x:\", x.shape)\n",
    "print(x)\n",
    "print(\"y:\", y.shape)\n",
    "print(y)\n",
    "# Permute the rows\n",
    "x = x[:, torch.randperm(x.shape[1])]\n",
    "print(\"x:\", x.shape)\n",
    "print(x)\n",
    "# Compute the eigenvalues\n",
    "new_y = torch.linalg.eigvals(x)\n",
    "print(\"y:\", new_y.shape)\n",
    "print(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:37:10.170428545Z",
     "start_time": "2023-08-03T13:37:09.572872387Z"
    }
   },
   "outputs": [],
   "source": [
    "class MatrixTokenizer(nn.Module):\n",
    "    def __init__(self, extra_space: int):\n",
    "        self.extra_space = extra_space\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x: Float[Tensor, \"batch row col\"]):\n",
    "        batch, rows, cols = x.shape\n",
    "        assert rows == cols\n",
    "        # Tokenize the rows and columns\n",
    "        columns = x.transpose(1, 2)\n",
    "        # Concatenate the rows and columns\n",
    "        out = torch.cat([x, columns], dim=1)\n",
    "        # Add zeros to the end of the tokens\n",
    "        out = torch.cat([out, torch.zeros(*out.shape[:2], self.extra_space, device=x.device)], dim=2)\n",
    "        return out\n",
    "       \n",
    "N = 4\n",
    "free_space = N\n",
    "d_model = N + free_space\n",
    "\n",
    "net = nn.Sequential(\n",
    "    MatrixTokenizer(free_space),\n",
    "    utils.SkipSequential(\n",
    "        utils.MultiAttention(d_model, 4, N),\n",
    "        utils.MLP(d_model, 4),\n",
    "        utils.DotProductLayer(d_model, 8, N),\n",
    "        utils.MultiAttention(d_model, 4, N),\n",
    "        # utils.MLP(d_model, 4),\n",
    "    ),\n",
    "    # Pooling layer\n",
    "    utils.PoolingLayer(\"flatten\"),\n",
    "    utils.MLP(d_model * N * 2, 4, out_dim=N),\n",
    "    # utils.PoolingLayer(\"max\"),\n",
    "    # utils.MLP(d_model, 4, out_dim=N),\n",
    ")\n",
    "\n",
    "torchinfo.summary(net, (100, N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T13:37:35.918355411Z",
     "start_time": "2023-08-03T13:37:10.870140990Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.train(net, lambda bs: gen_eigenvalues(bs, N), \n",
    "            batch_size=100,\n",
    "            log_every=200,\n",
    "            steps=2000,\n",
    "            loss_fn=torch.nn.MSELoss())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kasl",
   "language": "python",
   "name": "kasl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
