{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:47:57.894495378Z",
     "start_time": "2023-07-21T10:47:57.848662526Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from time import time\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from main import wrap_env, SimpleEnv, eval_agent, uniform_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:52:16.008256439Z",
     "start_time": "2023-07-21T10:52:15.962208607Z"
    }
   },
   "outputs": [],
   "source": [
    "random_goal_env = wrap_env(SimpleEnv(\n",
    "    size=5,\n",
    "    goal_pos=None,\n",
    "    agent_start_pos=None,\n",
    "    render_mode='rgb_array'\n",
    "))\n",
    "\n",
    "br_env = wrap_env(SimpleEnv(\n",
    "    size=5,\n",
    "    goal_pos=(-2, -2),\n",
    "    agent_start_pos=None,\n",
    "    render_mode='rgb_array'\n",
    "))\n",
    "\n",
    "print(\"Action space:\", random_goal_env.action_space)\n",
    "print(\"Observation space:\", random_goal_env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Policy:\", model.policy)\n",
    "# print(\"Model size:\", sum(p.numel() for p in model.policy.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(bottom_right_odds: int, steps: int = 50_000, general_env: gym.Env = random_goal_env, base_env: gym.Env = br_env):\n",
    "    n_envs = 1\n",
    "\n",
    "    # Define the training environment\n",
    "    goal_distrib = uniform_distribution((4, 4))\n",
    "    # There are 8 other positions, so odds are 8:br_odds*8 <=> 1:br_odds\n",
    "    goal_distrib[3, 3] = bottom_right_odds * 8\n",
    "    env = make_vec_env(lambda: wrap_env(SimpleEnv(\n",
    "        size=5,\n",
    "        goal_pos=goal_distrib,\n",
    "        # goal_pos=(-2, -2),\n",
    "        agent_start_pos=None,\n",
    "        # render_mode='rgb_array'\n",
    "    )), n_envs=n_envs)\n",
    "\n",
    "    # Define the policy network\n",
    "    policy = PPO(\"MlpPolicy\", env, verbose=1,\n",
    "               # learning_rate=0.01,\n",
    "               learning_rate=lambda f: 0.01 * f,\n",
    "               policy_kwargs=dict(net_arch=[30, 10]),\n",
    "               n_steps=2000 // n_envs,\n",
    "               batch_size=100,\n",
    "               n_epochs=40,\n",
    "               gamma=1,\n",
    "               tensorboard_log=\"run_logs\",\n",
    "                 device=\"cpu\" )\n",
    "    # Train the agent\n",
    "    policy.learn(total_timesteps=steps)\n",
    "\n",
    "    # Evaluate the agent\n",
    "    br_success_rate = eval_agent(policy, base_env, 1000)\n",
    "    success_rate = eval_agent(policy, general_env, 1000)\n",
    "    print(\"Bottom right success rate:\", br_success_rate)\n",
    "    print(\"Success rate:\", success_rate)\n",
    "\n",
    "    # Save the agent\n",
    "    name = f\"agents/ppo_{steps}steps_{success_rate*1000:03.0f}gen_{br_success_rate*1000:03.0f}br_{bottom_right_odds}odds\"\n",
    "    policy.save(name)\n",
    "    print(f\"Saved model to {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T10:54:26.679022624Z",
     "start_time": "2023-07-21T10:52:48.381022684Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # if i > 0:\n",
    "    #     sleep(30)\n",
    "    odds = np.random.randint(1, 10)\n",
    "    odds = 2\n",
    "    get_agent(odds, 50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
