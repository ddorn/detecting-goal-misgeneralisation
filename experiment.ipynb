{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:23:12.250343408Z",
     "start_time": "2023-07-27T11:23:12.219653197Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "from minigrid.core.constants import DIR_TO_VEC\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.torch_layers import (\n",
    "    FlattenExtractor,\n",
    "    BaseFeaturesExtractor,\n",
    ")\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import typeguard\n",
    "import jaxtyping\n",
    "\n",
    "import main as M\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:02.256391548Z",
     "start_time": "2023-07-27T11:25:02.225901883Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Action space:\", M.random_goal_env().action_space)\n",
    "print(\"Observation space:\", M.random_goal_env().observation_space)\n",
    "check_env(M.random_goal_env())\n",
    "\n",
    "agent_files = list(Path(\"agents\").glob(\"*.zip\"))\n",
    "print(\"Number of trained agents:\", len(agent_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Baseline\n",
    "\n",
    "Agent that always goes to the bottom right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T10:11:48.299293803Z",
     "start_time": "2023-07-27T10:11:44.188156114Z"
    }
   },
   "outputs": [],
   "source": [
    "env_size = 10\n",
    "M.Perfs.from_agent(\n",
    "    M.BottomRightAgent(can_turn=False), episodes=100, env_size=env_size, can_turn=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T18:33:43.302805820Z",
     "start_time": "2023-07-25T18:33:42.524399132Z"
    }
   },
   "outputs": [],
   "source": [
    "M.show_behavior(M.BottomRightAgent(), M.random_goal_env(env_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:25:14.481975192Z",
     "start_time": "2023-07-27T11:25:14.434630526Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformer\n",
    "\n",
    "env = M.random_goal_env(7)\n",
    "\n",
    "print(env.__class__.__mro__)\n",
    "print(env.observation_space)\n",
    "transformer.CustomActorCriticPolicy(\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    lr_schedule=lambda _: 0.01,\n",
    "    policy_kwargs=dict(d_model=32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:26:26.854489520Z",
     "start_time": "2023-07-27T11:25:28.734168154Z"
    }
   },
   "outputs": [],
   "source": [
    "import train\n",
    "import transformer\n",
    "\n",
    "env_size = 7\n",
    "env = M.random_goal_env(env_size)\n",
    "\n",
    "# For bottom_right_odds, None means uniform, 3 means three times more likely to be bottom right than anywhere else\n",
    "for _ in range(1):\n",
    "    policy, perfs = train.get_agent(\n",
    "        bottom_right_prob=0.8,\n",
    "        total_timesteps=100_000,\n",
    "        net_arch=(20,),\n",
    "        n_epochs=40,\n",
    "        n_steps=8_000 // 10,\n",
    "        batch_size=400,\n",
    "        learning_rate=0.001,\n",
    "        env_size=env_size,\n",
    "        n_envs=10,\n",
    "        can_turn=False,\n",
    "        # policy=transformer.CustomActorCriticPolicy,\n",
    "        # policy_kwargs=dict(features_extractor_class=transformer.CustomFeaturesExtractor, arch=dict(d_model=20, d_head=6, heads=3, layers=1)),\n",
    "        # use_wandb=True,\n",
    "        save=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T14:29:24.831063041Z",
     "start_time": "2023-07-26T14:29:24.182667490Z"
    }
   },
   "outputs": [],
   "source": [
    "M.show_behavior(policy, M.random_goal_env(env_size), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print size of the model\n",
    "print(\"Model size:\", sum(p.numel() for p in policy.policy.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Perfomances of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T17:00:28.914972908Z",
     "start_time": "2023-07-24T17:00:28.541232551Z"
    }
   },
   "outputs": [],
   "source": [
    "agent_files = list(Path(\"agents\").glob(\"*.zip\"))\n",
    "agent_files = list(Path(\"agents\").glob(\"ppo_7env*.zip\"))\n",
    "\n",
    "print(\"Number of agents:\", len(agent_files))\n",
    "\n",
    "\n",
    "def get_perfs(file: Path) -> M.Perfs:\n",
    "    if file.with_suffix(\".json\").exists():\n",
    "        return M.Perfs(**json.load(open(file.with_suffix(\".json\"), \"r\")))\n",
    "    else:\n",
    "        env_size = int(re.search(r\"(\\d+)env\", str(file)).group(1))\n",
    "        perf = M.Perfs.from_agent(PPO.load(file), file=str(file), env_size=env_size)\n",
    "        json.dump(dataclasses.asdict(perf), open(file.with_suffix(\".json\"), \"w\"))\n",
    "        return perf\n",
    "\n",
    "\n",
    "perfs = list(\n",
    "    Parallel(n_jobs=-3)(delayed(get_perfs)(file) for file in tqdm(agent_files))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-24T17:06:08.703999193Z",
     "start_time": "2023-07-24T17:06:08.615746794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot of the perfs, 2 by 2\n",
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        br_env=[p.br_env for p in perfs],\n",
    "        general_env=[p.general_env for p in perfs],\n",
    "        general_br_freq=[p.general_br_freq for p in perfs],\n",
    "        file=[str(p.info[\"file\"]) for p in perfs],\n",
    "        odds=[\n",
    "            int(re.search(r\"(\\d+)odds\", str(p.info[\"file\"])).group(1)) for p in perfs\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the perfs for agent with br_env > 0.9\n",
    "px.scatter(\n",
    "    df[df.br_env > 0.9],\n",
    "    x=\"general_br_freq\",\n",
    "    y=\"general_env\",\n",
    "    color=\"odds\",\n",
    "    hover_name=\"file\",\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    title=\"Performances of agents in a 5Ã—5 environment with random goals.\",\n",
    "    labels=dict(\n",
    "        general_br_freq=\"Probability of going in the bottom right corner, regardless of where the goal is\",\n",
    "        general_env=\"Probability of reaching the goal\",\n",
    "        odds=\"Odds of goal being<br>the bottom right corner\",\n",
    "    ),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:03:03.621634114Z",
     "start_time": "2023-07-27T11:03:03.599750355Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "policy_net = nn.Sequential(\n",
    "    policy.policy.features_extractor,\n",
    "    policy.policy.mlp_extractor.policy_net,\n",
    "    policy.policy.action_net,\n",
    ")\n",
    "value_net = nn.Sequential(\n",
    "    policy.policy.features_extractor,\n",
    "    policy.policy.mlp_extractor.value_net,\n",
    "    policy.policy.value_net,\n",
    ")\n",
    "\n",
    "print(f\"{env_size=}\")\n",
    "policy.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:18:09.687763479Z",
     "start_time": "2023-07-27T11:18:09.405258045Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"{env_size=}\")\n",
    "print(M.OneHotFullObsWrapper.MAPPING_NO_TURN)\n",
    "\n",
    "\n",
    "def mk_obs(agent_pos: tuple[int, int], goal_pos: tuple[int, int]):\n",
    "    out = torch.zeros(1, env_size - 2, env_size - 2, 4)\n",
    "    out[0, agent_pos[0], agent_pos[1], 1] = 1\n",
    "    out[0, goal_pos[0], goal_pos[1], 3] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "print(\"Facets: Value, Right, Down, Left, Up\")\n",
    "DIR_TO_VEC\n",
    "for goal_pos in [(1, 1), (2, 5), (3, 4), (6, 6), (7, 7)][::-1]:\n",
    "    obs = []\n",
    "    for i, j in np.ndindex(env_size - 2, env_size - 2):\n",
    "        obs.append(mk_obs((i, j), goal_pos))\n",
    "    obs = torch.cat(obs, dim=0)\n",
    "\n",
    "    values = value_net(obs)  # (64, 1)\n",
    "    logits = policy_net(obs).softmax(-1)  # (64, 4)\n",
    "\n",
    "    # Show heatmap of the 5 values\n",
    "    heat_map = torch.cat([values, logits], dim=1)  # (64, 5)\n",
    "    heat_map = heat_map.reshape(env_size - 2, env_size - 2, 5).detach().numpy()\n",
    "\n",
    "    px.imshow(\n",
    "        heat_map,\n",
    "        height=500,\n",
    "        title=f\"Value of each position in the environment with {goal_pos=}\",\n",
    "        facet_col=2,\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T11:12:44.952793082Z",
     "start_time": "2023-07-27T11:12:44.918396912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show logits\n",
    "\n",
    "obs = mk_obs((1, 1), (7, 7))\n",
    "logits = policy_net(obs)  # (1, 4)\n",
    "print(logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
