{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:42:09.538542540Z",
     "start_time": "2023-07-21T16:42:09.468601240Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "from joblib import Parallel, delayed\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import main as M\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:29:04.318564783Z",
     "start_time": "2023-07-21T16:29:04.285477656Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Action space:\", M.RANDOM_GOAL_ENV.action_space)\n",
    "print(\"Observation space:\", M.RANDOM_GOAL_ENV.observation_space)\n",
    "\n",
    "agent_files = list(Path(\"agents\").glob(\"*.zip\"))\n",
    "print(f\"Collected {len(agent_files)} agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:29:08.581409236Z",
     "start_time": "2023-07-21T16:29:08.555070902Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_agent():\n",
    "    file = random.choice(agent_files)\n",
    "    print(\"Loading agent:\", file)\n",
    "    return PPO.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:29:10.662657360Z",
     "start_time": "2023-07-21T16:29:10.619475634Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = get_random_agent()\n",
    "print(\"Policy:\", policy.policy)\n",
    "print(\"Model size:\", sum(p.numel() for p in policy.policy.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T13:48:03.360616056Z",
     "start_time": "2023-07-21T13:48:01.603204244Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = get_random_agent()\n",
    "# M.eval_agent(policy, M.RANDOM_GOAL_ENV, end_condition=lambda locals_: locals_[\"env\"].agent_pos == (3, 3))\n",
    "M.Perfs.from_agent(policy)\n",
    "# M.show_behavior(policy, M.RANDOM_GOAL_ENV, 40)\n",
    "# M.show_behavior(policy, M.BR_GOAL_ENV, 10)\n",
    "# M.eval_agent(policy, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T13:54:08.626426756Z",
     "start_time": "2023-07-21T13:51:31.488356296Z"
    }
   },
   "outputs": [],
   "source": [
    "perfs = list(\n",
    "    Parallel(n_jobs=-3)(\n",
    "        delayed(M.Perfs.from_agent)(PPO.load(file)) for file in tqdm(agent_files)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T14:08:09.133700638Z",
     "start_time": "2023-07-21T14:08:09.073655186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot of the perfs, 2 by 2\n",
    "br_env = [p.br_env for p in perfs]\n",
    "general_env = [p.general_env for p in perfs]\n",
    "general_br_freq = [p.general_br_freq for p in perfs]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    dict(\n",
    "        br_env=br_env,\n",
    "        general_env=general_env,\n",
    "        general_br_freq=general_br_freq,\n",
    "        file=[f.name for f in agent_files],\n",
    "    )\n",
    ")\n",
    "\n",
    "px.scatter(\n",
    "    df, x=\"general_br_freq\", y=\"general_env\", color=\"br_env\", hover_name=\"file\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T14:09:35.894456337Z",
     "start_time": "2023-07-21T14:09:35.245597467Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = PPO.load(\"agents/ppo_50000steps_612gen_998br_2odds_1689943572.zip\")\n",
    "M.show_behavior(agent, M.RANDOM_GOAL_ENV, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:17:15.770332043Z",
     "start_time": "2023-07-21T16:15:13.442320350Z"
    }
   },
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "policy = train.get_agent(5, 100_000, net_arch=(64, 32), env_size=6, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T16:17:41.137935799Z",
     "start_time": "2023-07-21T16:17:40.018034548Z"
    }
   },
   "outputs": [],
   "source": [
    "random_env = M.wrap_env(M.SimpleEnv(6, None, None, render_mode=\"rgb_array\"))\n",
    "M.show_behavior(policy, random_env, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T20:03:10.328885294Z",
     "start_time": "2023-07-21T20:03:10.262137616Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import click\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from main import wrap_env, SimpleEnv, eval_agent, uniform_distribution\n",
    "\n",
    "random_goal_env = lambda size: wrap_env(\n",
    "    SimpleEnv(size=size, goal_pos=None, agent_start_pos=None, render_mode=\"rgb_array\")\n",
    ")\n",
    "\n",
    "br_env = lambda size: wrap_env(\n",
    "    SimpleEnv(\n",
    "        size=size,\n",
    "        goal_pos=(size - 2, size - 2),\n",
    "        agent_start_pos=None,\n",
    "        render_mode=\"rgb_array\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def get_agent(\n",
    "    bottom_right_odds: int,\n",
    "    steps: int = 50_000,\n",
    "    n_envs: int = 1,\n",
    "    net_arch: tuple = (30, 10),\n",
    "    env_size: int = 5,\n",
    "    save: bool = True,\n",
    "):\n",
    "    # Define the training environment\n",
    "    goal_distrib = uniform_distribution((env_size - 1, env_size - 1))\n",
    "    # There are (envsize-2)**2-1 other positions\n",
    "    goal_distrib[env_size - 2, env_size - 2] = (\n",
    "        bottom_right_odds * (env_size - 2) ** 2 - 1\n",
    "    )\n",
    "    env = make_vec_env(\n",
    "        lambda: wrap_env(\n",
    "            SimpleEnv(\n",
    "                size=env_size,\n",
    "                goal_pos=goal_distrib,\n",
    "                # goal_pos=(-2, -2),\n",
    "                agent_start_pos=None,\n",
    "                # render_mode='rgb_array'\n",
    "            )\n",
    "        ),\n",
    "        n_envs=n_envs,\n",
    "    )\n",
    "\n",
    "    # Define the policy network\n",
    "    policy = DQN(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=0.001,\n",
    "        # learning_rate=lambda f: 0.001 * f,\n",
    "        # learning_rate=lambda f: 0.01 * f ** 1.5,\n",
    "        # policy_kwargs=dict(net_arch=net_arch),\n",
    "        # n_steps=2000 // n_envs,\n",
    "        # batch_size=100,\n",
    "        # n_epochs=40,\n",
    "        buffer_size=5_000,\n",
    "        learning_starts=5_000,\n",
    "        gradient_steps=100,\n",
    "        target_update_interval=1000,\n",
    "        exploration_fraction=0.2,\n",
    "        # exploration_final_eps=0.2,\n",
    "        # gamma=1,\n",
    "        tensorboard_log=\"run_logs\",\n",
    "        device=\"cpu\",\n",
    "    )\n",
    "    # Train the agent\n",
    "    policy.learn(total_timesteps=steps)\n",
    "\n",
    "    # Evaluate the agent\n",
    "    # perfs = M.Perfs.from_agent(policy, env_size=env_size, episodes=300)\n",
    "    br_success_rate = eval_agent(policy, br_env(env_size), 1000)\n",
    "    success_rate = eval_agent(policy, random_goal_env(env_size), 1000)\n",
    "    print(\"Bottom right success rate:\", br_success_rate)\n",
    "    print(\"Success rate:\", success_rate)\n",
    "\n",
    "    # Save the agent\n",
    "    if save:\n",
    "        name = f\"agents/ppo_{steps}steps_{success_rate * 1000:03.0f}gen_{br_success_rate * 1000:03.0f}br_{bottom_right_odds}odds_{time.time():.0f}\"\n",
    "        policy.save(name)\n",
    "        print(f\"Saved model to {name}\")\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T20:07:59.353876285Z",
     "start_time": "2023-07-21T20:03:11.072955407Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = get_agent(100, 50_000, net_arch=(64, 32), env_size=7, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T17:22:35.380359022Z",
     "start_time": "2023-07-21T17:22:35.359967649Z"
    }
   },
   "outputs": [],
   "source": [
    "policy.save(\"agents/old/learned_size7.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T17:21:35.807162574Z",
     "start_time": "2023-07-21T17:21:34.487773895Z"
    }
   },
   "outputs": [],
   "source": [
    "M.show_behavior(policy, random_goal_env(7), 40, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
