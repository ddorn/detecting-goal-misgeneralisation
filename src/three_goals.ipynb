{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69677c152f22a9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T17:05:12.017029458Z",
     "start_time": "2023-09-13T17:05:05.681001125Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T17:05:12.092543288Z",
     "start_time": "2023-09-13T17:05:12.019489005Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from random import randint\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from torch import nn\n",
    "from torchinfo import torchinfo\n",
    "from pprint import pprint\n",
    "\n",
    "import src as M\n",
    "\n",
    "# For plotly, to have larger images\n",
    "BIG = dict(width=1600, height=1600)\n",
    "ZERO_CENTERED = dict(color_continuous_scale=\"RdBu\", color_continuous_midpoint=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a966f3a89b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_SIZE = 4\n",
    "\n",
    "def mk_env_generator(full_color, weighted=False):\n",
    "    return M.wrap(\n",
    "        lambda: M.ThreeGoalsEnv(ENV_SIZE, step_reward=-0.003),\n",
    "        lambda e: M.ColorBlindWrapper(e, reduction='max', reward_indistinguishable_goals=True, disabled=full_color),\n",
    "        # lambda e: M.OneHotColorBlindWrapper(e, reward_indistinguishable_goals=True, disabled=full_color),\n",
    "        lambda e: M.WeightedChannelWrapper(e, weights=(1, 0.5, 1), disabled=not weighted),\n",
    "        lambda e: M.AddTrueGoalToObsFlat(e),\n",
    "        # lambda e: M.AddSwitch(e, 1, lambda _: 0),  # No switch, but we still use SwitchMLP as the architecture...\n",
    "    )\n",
    "mk_env = mk_env_generator(full_color=False)\n",
    "mk_env_full_color = mk_env_generator(full_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c67f04eee36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = M.ThreeGoalsEnv.constant(ENV_SIZE, true_goal={\"red\": 1, \"green\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b443ae4baaa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = mk_env_full_color()\n",
    "env = mk_env(const)\n",
    "\n",
    "print(env)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "check_env(env)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "if isinstance(obs, dict):\n",
    "    switch = obs['switch']\n",
    "    print(f\"{switch=}\")\n",
    "    obs = obs['obs']\n",
    "    \n",
    "print(f\"{obs.shape=}\")\n",
    "px.imshow(obs[:-3].reshape(ENV_SIZE, ENV_SIZE, 3)).show()\n",
    "print(obs[-3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062a6e93686dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show colorblind vs full color observations\n",
    "env = mk_env(const)\n",
    "obs_blind, _ = env.reset()\n",
    "env = mk_env_full_color(const)\n",
    "obs_full_color, _ = env.reset()\n",
    "env = mk_env_generator(False, True)(const)\n",
    "obs_weighted, _ = env.reset()\n",
    "\n",
    "img_blind = obs_blind[:-3].reshape(ENV_SIZE, ENV_SIZE, 3)\n",
    "img_full_color = obs_full_color[:-3].reshape(ENV_SIZE, ENV_SIZE, 3)\n",
    "img_weighted = obs_weighted[:-3].reshape(ENV_SIZE, ENV_SIZE, 3)\n",
    "\n",
    "# Show them on the same figure. Note obs are between 0 and 1\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Colorblind\", \"Full color\", \"Weighted blind\"))\n",
    "fig.add_trace(go.Image(z=img_blind * 255), row=1, col=1)\n",
    "fig.add_trace(go.Image(z=img_full_color * 255), row=1, col=2)\n",
    "fig.add_trace(go.Image(z=img_weighted * 255), row=1, col=3)\n",
    "fig.update_layout(width=1000, height=400, title=\"Observations\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b56ce3e540d56",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db6b9034e4a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = M.Split(-3,\n",
    "   left= nn.Sequential(\n",
    "       M.Rearrange(\"... (h w c) -> ... c h w\", h=ENV_SIZE, w=ENV_SIZE),\n",
    "       # M.PerChannelL1WeightDecay(\n",
    "           nn.LazyConv2d(8, 3, padding=1),\n",
    "           # weight_decay=0,\n",
    "           # name_filter=\"weight\",\n",
    "       # ),\n",
    "       nn.ReLU(),\n",
    "       nn.Conv2d(8, 8, 3, padding=1),\n",
    "       nn.ReLU(),\n",
    "       nn.Flatten(-3),\n",
    "   ),\n",
    "   right=nn.Identity(),\n",
    ")\n",
    "\n",
    "arch = nn.Sequential(\n",
    "    arch,\n",
    "    nn.LazyLinear(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "# arch = M.L1WeightDecay(arch, 0)\n",
    "\n",
    "print(arch)\n",
    "print(torchinfo.summary(arch, input_size=(7, *obs.shape), depth=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466be5caadc1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "# weight_decay = 1e-2\n",
    "seed = randint(0, 2**32 - 1)\n",
    "n_env = 4\n",
    "use_wandb = True\n",
    "\n",
    "# assert not isinstance(arch, M.L1WeightDecay), \"You forgot to re-run the arch definition\"\n",
    "# arch = M.L1WeightDecay(arch, l1_weight_decay)\n",
    "\n",
    "policy = PPO(\n",
    "    M.CustomActorCriticPolicy,\n",
    "    make_vec_env(mk_env, n_envs=n_env),\n",
    "    policy_kwargs=dict(\n",
    "        arch=arch,\n",
    "        # optimizer_kwargs=dict(weight_decay=0),\n",
    "    ),\n",
    "    n_steps=2_048 // n_env,\n",
    "    tensorboard_log=\"../run_logs\",\n",
    "    seed=seed,\n",
    "    learning_rate=lambda f: f * learning_rate,\n",
    "    device='cpu',\n",
    ")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.init(\n",
    "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "        save_code=True,\n",
    "        config=dict(\n",
    "            # l1_weight_decay=weight_decay,\n",
    "            arch=str(arch),\n",
    "            seed=seed,\n",
    "        ),\n",
    "        project=\"3goals-blind\",\n",
    "        notes=M.unique(\"\"\"\n",
    "Can I scale my results?\n",
    "614: Trying again with 1M steps on 7x7 env. -> learn slowly, in >1M steps. Still exibits preference for one color\n",
    "615: Added a step penalty and increased lr to 5e-4\n",
    "616: Decrease step penalty (-0.01 -> -0.003)\n",
    "\"\"\"))\n",
    "\n",
    "callbacks = [M.ProgressBarCallback(),\n",
    "             # M.WeightDecayCallback(lambda f: (1-f) * weight_decay),\n",
    "             M.LogChannelNormsCallback(),\n",
    "             ]\n",
    "if use_wandb:\n",
    "    callbacks.append(M.WandbWithBehaviorCallback(mk_env()))\n",
    "policy.learn(total_timesteps=1000_000, callback=callbacks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5a0f6d83e0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.lr_schedule = lambda _: 1e-4\n",
    "# policy.policy.mlp_extractor.policy_net.weight_decay = 3e-4\n",
    "policy.learn(total_timesteps=400_000, reset_num_timesteps=False, callback=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa4ef19630a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.make_stats(policy, mk_env(), n_episodes=10_000,\n",
    "             wandb_name=\"eval/blind\",\n",
    "             subtitle=\"Blind agent with blind inputs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6900cfa006dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.make_stats(policy, mk_env_full_color(),\n",
    "             n_episodes=10_000,\n",
    "             wandb_name=\"eval/full-color-non-weighted\",\n",
    "             subtitle=\"Blind agent with full color inputs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2f446e733e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 0\n",
    "M.evaluate(policy, mk_env(), n_episodes=400, show_n=3, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c422eb1efa3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.show_behavior(policy, mk_env_full_color(), 4, **BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73867436b9ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = []\n",
    "for i in range(6):\n",
    "    base_env = M.ThreeGoalsEnv.constant(ENV_SIZE, true_goal={\"red\": 1, \"green\": 1})\n",
    "    envs.append(mk_env(base_env))\n",
    "    envs.append(mk_env_full_color(base_env))\n",
    "        \n",
    "M.show_behavior(policy, envs, **BIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f45fc72e82ae17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load and Save models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bb1ef498be639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T15:06:29.708528775Z",
     "start_time": "2023-08-22T15:06:29.624125563Z"
    }
   },
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "exp = train.BlindThreeGoalsOneHot()\n",
    "policy, stats = exp.load(0)\n",
    "mk_env = exp.get_env(False)\n",
    "mk_env_full_color = exp.get_env(True)\n",
    "pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf80c3f9d3a4a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.make_stats(policy, mk_env_full_color(), n_episodes=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720492a6c4a2133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T15:03:42.878895134Z",
     "start_time": "2023-08-22T14:49:11.391348968Z"
    }
   },
   "outputs": [],
   "source": [
    "M.make_stats(policy, mk_env_full_color(), n_episodes=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257d5ad74724bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all models\n",
    "models_dir = Path(\"../models/3-goal-blind-one-hot\")\n",
    "for model_path in sorted(models_dir.glob(\"*.zip\")):\n",
    "    print(model_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbadfeb4c036e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"no-red-channel\"\n",
    "path = models_dir / f\"{name}.zip\"\n",
    "if path.exists():\n",
    "    print(\"Loading existing model\")\n",
    "    try:\n",
    "        previous_policy = policy  # Saved, in case I wanted to save it, but forgot to change the name\n",
    "    except NameError: \n",
    "        pass\n",
    "    policy = PPO.load(path)\n",
    "else:\n",
    "    print(f\"Saving model to {path}\")\n",
    "    try:\n",
    "        for name, m in policy.policy.named_modules():\n",
    "            if hasattr(m, \"logger\"):\n",
    "                print(\"Removing logger on\", m)\n",
    "                del m.logger\n",
    "        policy.save(path)\n",
    "    except Exception as e:\n",
    "        path.unlink()\n",
    "        # Without this I get TypeError: can't pickle LazyModule objects\n",
    "        # I don't know why, but my hack for the weight_decay seem to interfere with\n",
    "        # their saving mechanism\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae57831fa740ad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4133102ea0ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(x, symetric: bool = True, **kwargs):\n",
    "    h, w = x.shape[-2:]\n",
    "    if 'facet_col' in kwargs:\n",
    "        wrap = kwargs.get('facet_col_wrap', 1)\n",
    "        h *= np.ceil(x.shape[kwargs['facet_col']] / wrap)\n",
    "        w *= wrap\n",
    "    if symetric:\n",
    "        kwargs.setdefault(\"color_continuous_midpoint\", 0)\n",
    "        kwargs.setdefault(\"color_continuous_scale\", \"RdBu\")\n",
    "    width = 50 + w * 25\n",
    "    height = h * 25 + 50 * ('title' in kwargs)\n",
    "    while width < 500 and height < 500:\n",
    "        width *= 2\n",
    "        height *= 2\n",
    "    new = dict(\n",
    "        width=max(300, width),\n",
    "        height=max(300, height),\n",
    "        facet_row_spacing=0.01,\n",
    "        facet_col_spacing=0.01,\n",
    "    )\n",
    "    kwargs = {**new, **kwargs}\n",
    "    px.imshow(x, **kwargs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e157f586e0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_biases = policy.policy.mlp_extractor.switch_biases\n",
    "print(\"Biases shape:\", switch_biases.shape)\n",
    "print(\"Max abs bias:\", switch_biases.abs().max(dim=-1).values)\n",
    "imshow(switch_biases, title='Biases of the switch layers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f1569b1d07b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the three switch layers\n",
    "\n",
    "switch_layers_weights = policy.policy.mlp_extractor.switch_weights\n",
    "\n",
    "# shape of a switch (out_dim, row, col, obj_type)\n",
    "w1 = einops.rearrange(switch_layers_weights, 'agent out_dim (row col obj_type) -> agent obj_type out_dim row col', row=4, col=4)\n",
    "b1 = einops.repeat(policy.policy.mlp_extractor.switch_biases, 'agent out_dim -> agent 1 out_dim 4 1')\n",
    "\n",
    "avg = w1.mean(dim=0)\n",
    "TYPES = ['empty', 'agent', 'goal_red', 'goal_green', 'goal_blue']\n",
    "EMPTY, AGENT, RED, GREEN, BLUE = range(5)\n",
    "\n",
    "print(w1.shape, avg.shape)\n",
    "# d = w1[:, EMPTY] - avg[EMPTY] \n",
    "# d = avg\n",
    "\n",
    "d = w1[..., :-3]\n",
    "print(d.shape)\n",
    "# Add one black col\n",
    "d = torch.cat([d, torch.zeros(*d.shape[:-1], 1) + float('nan')], dim=-1)\n",
    "d = torch.cat([d, torch.zeros(*d.shape[:-2], 1, d.shape[-1]) + float('nan')], dim=-2)\n",
    "d = einops.rearrange(d, 'agent obj out row col -> out (agent row) (obj col)')[..., :-1, :]\n",
    "b1 = torch.cat([b1, torch.zeros(*b1.shape[:-2], 1, b1.shape[-1]) + float('nan')], dim=-2)\n",
    "b1 = einops.rearrange(b1, 'agent obj out row col -> out (agent row) (obj col)')[..., :-1, :]\n",
    "print(d.shape, b1.shape)\n",
    "d = torch.cat([d, b1], dim=-1)\n",
    "# Remove weights close to zero\n",
    "# d[abs(d) < 0.1] = float('nan')\n",
    "imshow(d[:16], title='First layer weights', facet_col=0, facet_col_wrap=4,\n",
    "          # height=4000,\n",
    "          # width=None,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451389ecd3d25bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(w1.flatten(2).mean(dim=2),\n",
    "          title=\"Mean of the weights of the switch layers\",\n",
    "          labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "       symetric=False,\n",
    "          )\n",
    "imshow(w1.flatten(2).abs().mean(dim=2), \n",
    "          title=\"Mean absolute value of the weights of the switch layers\",\n",
    "          labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "       symetric=False,\n",
    "          )\n",
    "imshow(w1.flatten(2).std(dim=2),\n",
    "            title=\"Std of the weights of the switch layers\",\n",
    "            labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "       symetric=False,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675396154733477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer: torch.nn.Linear = policy.policy.action_net\n",
    "last_weights = last_layer.weight.detach().cpu().clone()\n",
    "last_bias = last_layer.bias.detach().cpu().clone()\n",
    "net = policy.policy.mlp_extractor.policy_net.module\n",
    "\n",
    "weights = torch.cat([\n",
    "    last_weights.T @ net.switches[i].weight.detach().cpu().clone()\n",
    "    for i in range(3)\n",
    "], dim=0)\n",
    "imshow(weights)\n",
    "\n",
    "biases = torch.stack([net.switches[i].bias.detach().cpu() for i in range(3)], dim=1)\n",
    "imshow(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b34be96b254156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlations between rows of w2\n",
    "w2 = net.post_switch[1].weight.detach().cpu().clone()  # (64, 64)\n",
    "imshow(w2)\n",
    "w2 = w2 / w2.norm(dim=1, keepdim=True)\n",
    "corr = w2 @ w2.T\n",
    "\n",
    "# Cluster the correlations matrix\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial.distance as ssd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Compute and plot first dendrogram.\n",
    "fig = ff.create_dendrogram(\n",
    "    corr.numpy(),\n",
    "    orientation='left',\n",
    "    labels=list(range(64)),\n",
    "    linkagefun=lambda x: sch.linkage(x, 'single'),\n",
    "    distfun=lambda x: ssd.pdist(x, 'euclidean'),\n",
    ")\n",
    "fig.update_layout(width=1000, height=1000)\n",
    "fig.show()\n",
    "\n",
    "# Remove the diagonal\n",
    "corr[range(64), range(64)] = float('nan')\n",
    "px.imshow(corr, width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d24673e959d72d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Looking at the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77a4e502831d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "from pprint import pprint\n",
    "\n",
    "exp = train.BlindThreeGoalsOneHot()\n",
    "for idx in range(170, 190):\n",
    "    policy, stats = exp.load(idx)\n",
    "    if stats[\"seed\"] == 616_632_426:\n",
    "        print(idx)\n",
    "        pprint(stats)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd6cf7362bd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs: list[M.ThreeGoalsEnv]\n",
    "n = 2000\n",
    "envs = [exp.get_env(False)(M.ThreeGoalsEnv.constant()) for _ in range(n)]\n",
    "inputs = [env.reset()[0] for env in envs]\n",
    "with M.record_activations(policy.policy) as cache:\n",
    "    for i in tqdm(inputs):\n",
    "        policy.predict(i)\n",
    "    \n",
    "# cache.remove_batch_dim()\n",
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258fe49b4dfca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what the input looks like\n",
    "px.imshow(cache[\"left.0\"][0], facet_col=0).show()\n",
    "print(\"Goal\", cache[\"right\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7cf5ee7a5e4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the activations after the first conv2d, one for each output channel\n",
    "act = torch.stack([cache[f\"left.{i}\"] for i in (2, 4)])\n",
    "act = einops.rearrange(act, 'layer state out row col -> state (layer out) row col')\n",
    "act = torch.cat([act, cache[\"left.0\"], torch.zeros(n, 3, 4, 4)], dim=1)\n",
    "px.imshow(act[:20], facet_col=1, facet_col_wrap=8,\n",
    "          animation_frame=0, height=1000,\n",
    "          **ZERO_CENTERED).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55c213b058b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.stack([obs['obs'] for obs in inputs])\n",
    "switches = np.stack([obs['switch'] for obs in inputs])\n",
    "print(\"Observations shape:\", observations.shape)\n",
    "print(\"Switches shape:\", switches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7feb120e25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_positions = torch.tensor([e.goal_positions for e in envs]).float()\n",
    "agent_positions = torch.tensor([e.agent_pos for e in envs]).float()\n",
    "red_goals = goal_positions[:, 0]\n",
    "green_goals = goal_positions[:, 1]\n",
    "blue_goals = goal_positions[:, 2]\n",
    "dist_to_red = torch.linalg.norm(agent_positions - red_goals, dim=1, ord=1)\n",
    "dist_to_green = torch.linalg.norm(agent_positions - green_goals, dim=1, ord=1)\n",
    "dist_to_blue = torch.linalg.norm(agent_positions - blue_goals, dim=1, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5204a4f31746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to predict the blue position from the activations of the first conv\n",
    "\n",
    "act = cache[\"left.4\"]\n",
    "act = einops.rearrange(act, 'batch out row col -> batch (out row col)')\n",
    "to_predict = blue_goals[:, 1]\n",
    "to_predict = (blue_goals - agent_positions)[:, 0]\n",
    "# to_predict = agent_positions[:, 0]\n",
    "to_predict = torch.minimum(dist_to_red, dist_to_green)\n",
    "# to_predict = to_predict - to_predict.mean(dtype=float)\n",
    "\n",
    "# reg = LinearRegression().fit(act, to_predict)\n",
    "reg = Lasso(1e-2).fit(act, to_predict)\n",
    "print(reg.score(act, to_predict))\n",
    "\n",
    "predictions = reg.predict(act)\n",
    "fig = px.scatter(x=to_predict, y=predictions,\n",
    "           labels=dict(x=\"Predicted blue goal position\", y=\"True blue goal position\"),\n",
    "           **ZERO_CENTERED)\n",
    "# Add x=y line\n",
    "minimum = min(to_predict.min(), predictions.min())\n",
    "maximum = max(to_predict.max(), predictions.max())\n",
    "fig.add_shape(type=\"line\", x0=minimum, y0=minimum, x1=maximum, y1=maximum,\n",
    "              line=dict(color=\"red\"))\n",
    "fig.show()\n",
    "\n",
    "# Plot histogram of the coefficients\n",
    "# fig = px.histogram(reg.coef_, nbins=100,\n",
    "#                    labels=dict(x=\"Coefficient\", y=\"Count\"))\n",
    "# fig.show()\n",
    "\n",
    "# Plot the coefficients (output=8 row=4 col=4)\n",
    "print(reg.intercept_)\n",
    "coef = einops.rearrange(reg.coef_, '(out row col) -> out row col', out=8, row=4, col=4)\n",
    "px.imshow(coef, facet_col=0, facet_col_wrap=4, **ZERO_CENTERED).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417f1c39b6b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation between each act and red_goal.x\n",
    "def one_hot_encode(arr, maxi=4):\n",
    "    # Set up one-hot encoding array\n",
    "    one_hot = np.zeros((*arr.shape, maxi))\n",
    "    # Populate the one-hot encoding array        \n",
    "    np.put_along_axis(one_hot, arr[..., None], 1, axis=-1)\n",
    "    return one_hot\n",
    "\n",
    "# to_check = goal_positions.flatten(1)\n",
    "# to_check = one_hot_encode(to_check)\n",
    "to_check = np.concatenate([\n",
    "    goal_positions.flatten(1),\n",
    "    agent_positions], \n",
    "    axis=-1)\n",
    "\n",
    "for name in (\"switches.0\", \"switches.1\"):\n",
    "    act = cache[name]\n",
    "    corrs = np.corrcoef(act, to_check, rowvar=False)\n",
    "    # remove the diagonal\n",
    "    corrs[range(corrs.shape[0]), range(corrs.shape[0])] = 0\n",
    "    imshow(corrs[32:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3100b8c45e5d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_red_blind = np.corrcoef(cache['switches.0'], goal_positions[:, 0], rowvar=False)\n",
    "corr_blue_color = np.corrcoef(cache['switches.1'], goal_positions[:, 2], rowvar=False)\n",
    "corr_red_blind = corr_red_blind[32:, :-2]\n",
    "corr_blue_color = corr_blue_color[32:, :-2]\n",
    "corrs = einops.rearrange([corr_red_blind, corr_blue_color], \n",
    "                         \"type dim neuron -> (dim type) neuron\")\n",
    "\n",
    "imshow(corrs)\n",
    "imshow(corr_red_blind)\n",
    "imshow(corr_blue_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a040d6c1950a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = next(m for m in policy.policy.modules() if isinstance(m, torch.nn.Conv2d))\n",
    "with torch.no_grad():\n",
    "    conv1.weight[:, 3] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15fad411bb6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_first_conv(policy):\n",
    "    conv1 = next(m for m in policy.policy.modules() if isinstance(m, torch.nn.Conv2d))\n",
    "    conv1 = conv1.weight.detach().numpy()\n",
    "    \n",
    "    in_channels = conv1.shape[1]\n",
    "    in_channel_names = [\"Empty\", \"Agent\", \"Red\", \"Green\", \"Blue\"][-in_channels:]\n",
    "\n",
    "    # Per channel norms\n",
    "    norms = np.linalg.norm(conv1, axis=(2, 3))\n",
    "    print(np.linalg.norm(conv1))\n",
    "    px.imshow(norms, \n",
    "              title=\"Norms of the weights of the first convolutional layer\",\n",
    "                labels=dict(x=\"Input channel\", y=\"Output channel\"),\n",
    "              x=in_channel_names,\n",
    "              width=500,\n",
    "              **ZERO_CENTERED).show()\n",
    "\n",
    "    conv1 = einops.repeat(conv1, \"out in row col -> out row (in col)\")\n",
    "    px.imshow(conv1, facet_col=0,\n",
    "              **ZERO_CENTERED,\n",
    "              # zmax=2, zmin=-2,\n",
    "              facet_col_wrap=4).show()\n",
    "    \n",
    "    \n",
    "show_first_conv(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab25e0bc205b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a PCA on the data\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "file = \"../data.csv\"\n",
    "with open(file, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data = pd.DataFrame(data)\n",
    "del data[\"Name\"]\n",
    "del data[\"_wandb\"]\n",
    "data = data.astype(float)\n",
    "x_axis = \"eval/full_color/true_goal_red/end_type_red\"\n",
    "y_axis = \"eval/full_color/true_goal_red/end_type_green\"\n",
    "\n",
    "# Print mean on the x and y axis\n",
    "n_points = len(data)\n",
    "print(\"Number of points\", n_points)\n",
    "print(\"Mean on x axis\", data[x_axis].mean())\n",
    "print(\"Mean on y axis\", data[y_axis].mean())\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "fitted = pca.fit_transform(data[[x_axis, y_axis]])\n",
    "\n",
    "px.histogram(fitted, marginal=\"rug\", title=f\"PCA on Red vs. Green probas (n={n_points})\",\n",
    "             nbins=70,\n",
    "             width=1000,\n",
    "             ).show()\n",
    "\n",
    "px.histogram(data[[x_axis, y_axis]],\n",
    "             barmode=\"overlay\",\n",
    "             marginal=\"rug\",\n",
    "             nbins=70,\n",
    "             width=1000,\n",
    "             ).show()\n",
    "                \n",
    "fig = px.histogram(data[x_axis] - data[y_axis],\n",
    "             title=f\"Diff between red and green probas (n={n_points})\",\n",
    "             # Normalized histogram\n",
    "             histnorm=\"probability density\",\n",
    "             marginal=\"rug\",\n",
    "             nbins=70,\n",
    "             width=1000,\n",
    "             )\n",
    "# Add the pdf of a normal distribution\n",
    "from plotly import graph_objects as go\n",
    "from scipy import stats\n",
    "mean = (data[x_axis] - data[y_axis]).mean()\n",
    "std = (data[x_axis] - data[y_axis]).std()\n",
    "x = np.linspace(mean - 3 * std, mean + 3 * std, 100)\n",
    "y = stats.norm.pdf(x, mean, std)\n",
    "fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Normal distribution\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63bc022a145ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare last histogram with a normal distribution\n",
    "mean = (data[x_axis] - data[y_axis]).mean()\n",
    "std = (data[x_axis] - data[y_axis]).std()\n",
    "\n",
    "# Generate samples from a normal distribution\n",
    "samples = np.random.normal(mean, std, size=n_points)\n",
    "# Plot the same histogram\n",
    "px.histogram(samples,\n",
    "             title=f\"Gaussian samples with the same mean & std (n={n_points})\",\n",
    "             marginal=\"rug\",\n",
    "             nbins=70,\n",
    "             width=1000,\n",
    "             ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc844a9a5a8454e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Loading and plotting metrics of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af1704dc948d2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T18:23:32.735644212Z",
     "start_time": "2023-09-13T18:23:31.823931020Z"
    }
   },
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "train.Experiment.show_all_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705bb9d09cf6841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:31:12.920818503Z",
     "start_time": "2023-09-13T21:31:10.221383005Z"
    }
   },
   "outputs": [],
   "source": [
    "train.MODELS_DIR = train.ROOT / \"models\"\n",
    "# train.MODELS_DIR = train.ROOT / \"cam_fs\" / \"models\"\n",
    "Exp = train.BlindThreeGoals\n",
    "stats = Exp.load_all_checkpoints_stats()\n",
    "print(len(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42359686985b9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = train.BlindThreeGoalsOneHot\n",
    "models, stats = Exp.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa39fa6c7dae92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:35:39.499448574Z",
     "start_time": "2023-09-13T21:35:39.293866192Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_red_stats(data: dict):\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            data[\"eval\"][f\"eval/full_color/true_goal_red/end_type_{type_}\"]\n",
    "            for type_ in [\"red\", \"green\", \"blue\", \"no goal\"]\n",
    "        ]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        return [\n",
    "            data[\"eval\"][\"full_color\"][\"true_goal_red\"][f\"end_type_{type_}\"]\n",
    "            for type_ in [\"red\", \"green\", \"blue\", \"no goal\"]\n",
    "        ]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return [\n",
    "            data[\"eval\"][\"full_color_non_weighted\"][\"true_goal_red\"][f\"end_type_{type_}\"]\n",
    "            for type_ in [\"red\", \"green\", \"blue\", \"no goal\"]\n",
    "        ]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return data[\"stats_full_color\"][0]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    print(\"Could not find the red stats in\")\n",
    "    pprint(data)\n",
    "    raise KeyError\n",
    "\n",
    "# full_color_probas = np.array([get_red_stats(d) for d in tqdm(stats)])\n",
    "stat_array = [[get_red_stats(d) for d in model_stats] for model_stats in tqdm(stats)]\n",
    "full_color_probas_by_run = np.array(stat_array)\n",
    "full_color_probas = full_color_probas_by_run.reshape(-1, 4)\n",
    "\n",
    "red_proba = full_color_probas[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497de10b975adac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:33:40.944420231Z",
     "start_time": "2023-09-13T21:33:40.685716698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the norm of the red channel in the first conv layer\n",
    "def get_norms(model):\n",
    "    conv1 = next(m for m in model.policy.modules() if isinstance(m, torch.nn.Conv2d))\n",
    "    conv1 = conv1.weight.detach().numpy()\n",
    "    conv1 = einops.rearrange(conv1, \"out input row col -> input (out row col)\")\n",
    "    norms = np.linalg.norm(conv1, axis=1)\n",
    "    return norms\n",
    "\n",
    "\n",
    "channel_1 = 2  # red\n",
    "channel_2 = 3  # green\n",
    "channel_norms = np.stack([get_norms(model) for model in tqdm(models)])\n",
    "\n",
    "px.scatter(x=channel_norms[:, channel_1], y=red_proba,\n",
    "           labels=dict(x=\"Norm of the red channel\", y=\"Probability of red\"),\n",
    "           title=\"Norm of the red channel vs probability of red\",\n",
    "           width=1000).show()\n",
    "\n",
    "minx = min(full_color_probas[:, 1].min(), red_proba.min())\n",
    "maxx = max(full_color_probas[:, 1].max(), red_proba.max())\n",
    "# Making it symetrical around 0.5\n",
    "minx = min(minx, 1 - maxx)\n",
    "maxx = max(maxx, 1 - minx)\n",
    "\n",
    "fig = px.scatter(x=full_color_probas[:, 1], y=red_proba,\n",
    "                 color=list(range(len(full_color_probas))),\n",
    "                 # Link the dots\n",
    "                 # color=full_color_probas[:, 3],\n",
    "                 range_x=(minx, maxx),\n",
    "                 range_y=(minx, maxx),\n",
    "           labels=dict(x=\"Probability of green\", y=\"Probability of red\", color=\"No goal\"),\n",
    "           title=f\"Behavior distribution when the target tile is red (n={len(full_color_probas)})\",\n",
    "           width=1000, height=1000)\n",
    "M.add_line(fig, \"y=1-x\")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "px.histogram(red_proba, marginal=\"rug\", \n",
    "             nbins=70,\n",
    "             title=\"Histogram of the probability of red\", width=1000).show()\n",
    "\n",
    "\n",
    "to_explain = red_proba\n",
    "# Plot the correlation between channel norms and probabilities\n",
    "corrs = np.corrcoef(channel_norms, to_explain, rowvar=False)\n",
    "px.imshow(corrs, \n",
    "          title=\"Correlation between channel norms and probabilities\",\n",
    "          labels=dict(x=\"Input channel\", y=\"Output channel\"),\n",
    "          x=[\"Empty\", \"Agent\", \"Red\", \"Green\", \"Blue\", \"Red prob\"][-len(corrs):],\n",
    "          width=1000,\n",
    "          **ZERO_CENTERED).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b84cce3655d68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T18:44:57.645444642Z",
     "start_time": "2023-09-13T18:44:57.488121095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the proba of red against the position in the list on one plot\n",
    "px.scatter(x=range(len(red_proba)), y=red_proba,\n",
    "           labels=dict(x=\"Model\", y=\"Probability of red\"),\n",
    "           title=\"Probability of red vs model\",\n",
    "           width=1000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ef2973fa9bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T21:38:47.422398550Z",
     "start_time": "2023-09-13T21:38:47.218874250Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = np.array([[d[\"timesteps\"] for d in model_stats] for model_stats in stats])\n",
    "checkpoint = checkpoint.reshape(-1)\n",
    "\n",
    "# Plot the proba of red against the proba of green, colored by the checkpoint\n",
    "px.scatter(x=full_color_probas[:, 1], y=red_proba,\n",
    "           color=checkpoint,\n",
    "           labels=dict(x=\"Probability of green\", y=\"Probability of red\", color=\"Checkpoint\"),\n",
    "           title=\"Probability of red vs probability of green\",\n",
    "           width=1000).show()\n",
    "\n",
    "# Plot mean and std of the proba of red for each run\n",
    "mean = full_color_probas_by_run.mean(axis=0)\n",
    "std = full_color_probas_by_run.std(axis=0)\n",
    "px.scatter(x=checkpoint[:len(std)], y=mean[:, 0],\n",
    "           error_y=std[:, 0],\n",
    "           labels=dict(x=\"Run\", y=\"Mean probability of red\", error_y=\"Std of the probability of red\"),\n",
    "           title=\"Mean probability of red vs run\",\n",
    "           width=1000).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23935459934362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a linear regression from the channel norms to the probabilities\n",
    "import utils\n",
    "\n",
    "reg = utils.show_fit(LinearRegression(), channel_norms, to_explain,\n",
    "                     title=f\"Predicted probability of red vs true probability of red using a linear regression on the channel norms\",\n",
    "                     xaxis=\"True probability of red\",\n",
    "                     yaxis=\"Predicted probability of red\")\n",
    "print(\"Coefficients:\", reg.coef_)\n",
    "print(\"Intercept:\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f4aed4e275ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x=red_proba,\n",
    "    y=channel_norms[:, 2] - channel_norms[:, 3],\n",
    "           title=\"Norm of the red channel vs probability of red\",\n",
    "           width=1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a74789e96b73cc2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Predicting which goal will be reached by an agent\n",
    "Here, we try to predict the red frequency from the the first convolutional layer, \n",
    "using a linear regression. \n",
    "Input: one output channel of the first convolutional layer\n",
    "Output: probability of reaching the red goal of the corresponding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44575cf8bab63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5e96813f2f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = M.wrap(\n",
    "    M.ThreeGoalsEnv.constant(),\n",
    "    lambda e: M.OneHotColorBlindWrapper(e, reward_indistinguishable_goals=True),\n",
    "    lambda e: M.AddTrueGoalToObsFlat(e),\n",
    ")()\n",
    "\n",
    "obs, _ = env.reset(seed=36)\n",
    "with M.record_activations(models[0].policy) as cache:\n",
    "    models[0].predict(obs)\n",
    "print(cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f04df20026ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "# noinspection PyUnreachableCode\n",
    "def get_inputs(model):\n",
    "    convs = [m.weight.detach() for m in model.policy.modules() if isinstance(m, torch.nn.Conv2d)]\n",
    "    linears = [m.weight.detach() for m in model.policy.modules() if isinstance(m, torch.nn.Linear)]\n",
    "\n",
    "    conv1, conv2 = convs\n",
    "    lin1, lin2 = linears[:2]\n",
    "    \n",
    "    return torch.linalg.vector_norm(conv1, dim=(0, 2, 3))\n",
    "    \n",
    "    with M.record_activations(model.policy) as cache:\n",
    "        model.predict(obs)\n",
    "    cache.apply(torch.flatten)\n",
    "    return torch.cat([\n",
    "        # cache['left.2'].flatten(),\n",
    "        # conv1.flatten(),\n",
    "        # conv2.flatten(),\n",
    "        lin1.flatten(),\n",
    "        lin2.flatten(),\n",
    "        # cache['left.2'],\n",
    "        # cache['left.4'],\n",
    "        cache[\"Split\"],\n",
    "        cache['dule.2'],\n",
    "        cache['dule.4'],\n",
    "    ])\n",
    "    return cache['left.2']\n",
    "\n",
    "predictors = np.stack([get_inputs(model).flatten() for model in models])\n",
    "to_predict = full_color_probas[:, 0]\n",
    "\n",
    "if predictors.ndim == 3:\n",
    "    to_predict = einops.repeat(to_predict, \"n -> (n c)\", c=predictors.shape[1])\n",
    "    predictors = predictors.reshape(-1, predictors.shape[-1])\n",
    "    \n",
    "\n",
    "# Split the data into train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(flat_conv1s, to_predict, test_size=0.2, random_state=42)\n",
    "\n",
    "# augment the training data by adding some permutations of the output channels\n",
    "# to_add = []\n",
    "# for i in range(30):\n",
    "#     by_out_channel = einops.rearrange(X_train, \"model (out rest) -> out model rest\", out=n_out_channels)\n",
    "#     by_out_channel = by_out_channel[np.random.permutation(n_out_channels)]\n",
    "#     by_out_channel = einops.rearrange(by_out_channel, \"out model rest -> model (out rest)\")\n",
    "#     to_add.append(by_out_channel)\n",
    "# X_train = np.concatenate([X_train] + to_add)\n",
    "# y_train = np.concatenate([y_train] * (len(to_add) + 1))\n",
    "# \n",
    "\n",
    "\n",
    "reg = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(0.0001),\n",
    "    MLPRegressor(hidden_layer_sizes=(64, ), alpha=0.01)\n",
    "][0]\n",
    "\n",
    "utils.show_fit(reg, predictors, to_predict,\n",
    "               title=f\"Predicted probability of red vs true probability of red using {reg}\",\n",
    "               xaxis=\"True probability of red\",\n",
    "               yaxis=\"Predicted probability of red\")\n",
    "\n",
    "px.imshow(reg.coef_.reshape(8, 5),\n",
    "          title=\"Coefficients of the linear regression\",\n",
    "          # facet_col=0,\n",
    "          width=1000,\n",
    "          **ZERO_CENTERED).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7e28a8bef06ba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Finding how they make their decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57226bb7136bd360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T10:07:46.387717748Z",
     "start_time": "2023-09-13T10:07:46.203708360Z"
    }
   },
   "outputs": [],
   "source": [
    "Exp = train.BlindThreeGoalsOneHot\n",
    "\n",
    "model, stat = Exp.load(42)\n",
    "M.make_stats(model, Exp().get_eval_env().constant(), 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea96f84bfe8c25f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:24:10.731917981Z",
     "start_time": "2023-09-13T11:24:10.532710517Z"
    }
   },
   "outputs": [],
   "source": [
    "def stats_per_cell(policy: PPO, env):\n",
    "    unwrapped = env.unwrapped\n",
    "    assert isinstance(unwrapped, M.ThreeGoalsEnv)\n",
    "    probas = torch.zeros(unwrapped.height, unwrapped.width, 4) + float('nan')\n",
    "    values = torch.zeros(unwrapped.height, unwrapped.width) + float('nan')\n",
    "    for x in range(unwrapped.width):\n",
    "        for y in range(unwrapped.height):\n",
    "            if (x, y) in unwrapped.goal_positions:\n",
    "                continue\n",
    "            unwrapped.agent_start = (x, y)\n",
    "            obs, _ = env.reset()\n",
    "            obs = torch.from_numpy(obs)\n",
    "            distr = policy.policy.get_distribution(obs)\n",
    "            probas[y, x] = distr.distribution.probs.detach()\n",
    "            \n",
    "            values[y, x] = policy.policy.predict_values(obs).detach()\n",
    "            \n",
    "    # Render the env\n",
    "    img = env.render()\n",
    "    px.imshow(np.flip(img, 0), title=\"Environment\", width=500).show()\n",
    "    \n",
    "    # Plot the heatmap of the values and arrows between the cells of length corresponding to the probas\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Heatmap(\n",
    "        z=values,\n",
    "        colorscale=\"Mint\",\n",
    "        colorbar=dict(title=\"Value\"),\n",
    "    ))\n",
    "    # Add arrows\n",
    "    for x in range(unwrapped.width):\n",
    "        for y in range(unwrapped.height):\n",
    "            if (x, y) in unwrapped.goal_positions:\n",
    "                continue\n",
    "            for i, (dx, dy) in enumerate(unwrapped.DIR_TO_VEC):\n",
    "                proba = probas[y, x, i].item()\n",
    "                if abs(proba) < 0.1:\n",
    "                    continue\n",
    "                    \n",
    "                fig.add_annotation(\n",
    "                    text=\"\",\n",
    "                    ax=x,\n",
    "                    ay=y,\n",
    "                    x=x+ dx * proba / 2,\n",
    "                    y=y + dy * proba / 2,\n",
    "                    xref=\"x\", yref=\"y\", axref=\"x\", ayref=\"y\",\n",
    "                    showarrow=True,\n",
    "                    arrowhead=4,\n",
    "                    arrowsize=1,\n",
    "                    arrowwidth=3,\n",
    "                    arrowcolor=\"red\",\n",
    "                )\n",
    "    # Draw a filled colored square on the 3 goal cells\n",
    "    for i, color in enumerate([\"#ff0000\", \"#00ff00\", \"#0000ff\"]):\n",
    "        x, y = unwrapped.goal_positions[i]\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=x - 0.5, y0=y - 0.5, x1=x + 0.5, y1=y + 0.5,\n",
    "            fillcolor=color,\n",
    "            line=dict(color=color, width=0),\n",
    "            layer=\"above\",\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"Values and probabilities of the policy\",\n",
    "        xaxis=dict(title=\"x\"),\n",
    "        yaxis=dict(title=\"y\"),\n",
    "        width=500,\n",
    "        height=500,\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    return probas, values\n",
    "\n",
    "env = Exp().get_env(True)(M.ThreeGoalsEnv.constant(4, 'red'))\n",
    "\n",
    "stats_per_cell(model, env);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35462b0526b10e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:17:52.264627382Z",
     "start_time": "2023-09-13T11:15:01.911384429Z"
    }
   },
   "outputs": [],
   "source": [
    "agent_pos, goals_pos, end_type, true_goal = M.destination_stats(model, Exp().get_eval_env(), 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dccb3c06345434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:18:08.602470940Z",
     "start_time": "2023-09-13T11:18:08.043981722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print all the shapes\n",
    "print(\"Agent pos shape:\", agent_pos.shape)\n",
    "print(\"Goals pos shape:\", goals_pos.shape)\n",
    "print(\"End type shape:\", end_type.shape)\n",
    "print(\"True goal shape:\", true_goal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d4bb5a32f3457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:18:16.790614945Z",
     "start_time": "2023-09-13T11:18:16.689833963Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET = 1\n",
    "\n",
    "vec_to_goals = (goals_pos - agent_pos[:, None, :])\n",
    "end_on_target = end_type == TARGET\n",
    "red_or_green = end_type < 2\n",
    "\n",
    "# Find the distance to red and green goals\n",
    "dist_to_goal = torch.linalg.vector_norm(vec_to_goals.float(), dim=2, ord=1).long()\n",
    "dist_to_goal.shape, red_or_green.shape, end_on_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458284c5da5ecb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:18:19.950604338Z",
     "start_time": "2023-09-13T11:18:19.683975299Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = M.show_fit(\n",
    "    LogisticRegression(), \n",
    "    dist_to_goal[red_or_green][:, [0, 1]], \n",
    "    end_on_target[red_or_green],\n",
    "    title=\"Predicting whether the policy goes to red or green end depending on the distance to the target cells\", \n",
    "    xaxis=\"Prediction: does it go to green?\",\n",
    "    yaxis=\"True: does it go to green?\",\n",
    "    classification=True,\n",
    ")\n",
    "\n",
    "print(reg.coef_, reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c65aae1c901a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:20:05.784798720Z",
     "start_time": "2023-09-13T11:20:03.008345994Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the frequency of going to each end type, as a heatmap x=distance to red, y=distance to green\n",
    "\n",
    "plot_only_red_green = True\n",
    "n_plots = 2 if plot_only_red_green else 4\n",
    "\n",
    "max_dist = dist_to_goal.max().item() + 1\n",
    "frequency = torch.full((n_plots, max_dist, max_dist), float('nan'))\n",
    "counts = torch.full((n_plots, max_dist, max_dist), 0)\n",
    "\n",
    "for target in range(n_plots):\n",
    "    for x in range(1, max_dist):\n",
    "        for y in range(1, max_dist):\n",
    "            correct_target = (end_type == target)[red_or_green]\n",
    "            correct_x = (dist_to_goal[:, 0] == x)[red_or_green]\n",
    "            correct_y = (dist_to_goal[:, 1] == y)[red_or_green]\n",
    "            frequency[target, y, x] = correct_target[correct_x & correct_y].float().mean()\n",
    "            counts[target, y, x] = len(correct_target[correct_x & correct_y])\n",
    "            \n",
    "        \n",
    "fig = px.imshow(frequency,\n",
    "                title=\"Frequency of going to each end type, as a heatmap x=distance to red, y=distance to green\",\n",
    "                labels=dict(x=\"Distance to red\", y=\"Distance to green\", color=\"Frequency\"),\n",
    "                facet_col=0, height=1000,\n",
    "                zmin=0, zmax=1, color_continuous_scale=\"Blues\")\n",
    "# Set facet labels\n",
    "for i, label in enumerate([\"Red\", \"Green\", \"Blue\", \"No goal\"][:n_plots]):\n",
    "    fig.layout.annotations[i].text = f\"Ended on {label}\"\n",
    "    \n",
    "# Add percentage labels\n",
    "for i in range(n_plots):\n",
    "    for j in range(max_dist):\n",
    "        for k in range(max_dist):\n",
    "            value = frequency[i, j, k]\n",
    "            if not np.isnan(value):\n",
    "                fig.add_annotation(\n",
    "                    x=j, y=k, text=f\"{value:.0%}\", showarrow=False,\n",
    "                    col=i, row=1,\n",
    "                    font=dict(color=\"white\" if value > 0.5 else \"black\", size=20)\n",
    "                )\n",
    "                fig.add_annotation(\n",
    "                    x=j, y=k+0.2, text=f\"n={counts[i, k, j]}\", showarrow=False,\n",
    "                    col=i, row=0,\n",
    "                    font=dict(color=\"white\" if value > 0.5 else \"black\", size=10)\n",
    "                )\n",
    "   \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf7796ca181cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there some cells that are prefered?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29476c54f9d6afa1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Show what the baseline does \n",
    "\n",
    "Here the baseline of going to the red goal while avoiding the blue and ignoring the green one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d64acb5fe75d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = mk_env_full_color()\n",
    "obs, _ = env.reset()\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195e60ba03afddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselines import Baseline\n",
    "class BaselineAvoidGreen(Baseline):\n",
    "    def _predict(self, obs, deterministic=False):\n",
    "        grid: np.ndarray = obs[:-3].reshape(4, 4, -1)\n",
    "        \n",
    "        agent_pos = self.find(grid, [1, 1, 1])\n",
    "        red_pos = self.find(grid, [1, 0, 0])\n",
    "        green_pos = self.find(grid, [0, 1, 0])\n",
    "        blue_pos = self.find(grid, [0, 0, 1])\n",
    "        \n",
    "        obstacles = np.zeros((4, 4), dtype=bool)\n",
    "        obstacles[blue_pos] = True\n",
    "        \n",
    "        path = self.find_path(agent_pos, red_pos, obstacles)\n",
    "        if path:\n",
    "            action = self.direction_to(agent_pos, path[1])\n",
    "            return action\n",
    "        else:\n",
    "            return self.random_action()\n",
    "\n",
    "# M.evaluate(BaselineAvoidGreen(), env, 1, height=400, width=1000)\n",
    "# M.evaluate(BaselineAvoidGreen(), env)\n",
    "M.make_stats(BaselineAvoidGreen(), env, 100000, \"Perfect agent going to red, avoiding blue, ignoring green\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1854974068675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1010ff0b27931357",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Try to split the network into the red, green and blue parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625129e70c9d923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T12:26:59.197794279Z",
     "start_time": "2023-09-05T12:26:53.269294413Z"
    }
   },
   "outputs": [],
   "source": [
    "import train\n",
    "Exp = train.BlindThreeGoalsOneHot\n",
    "\n",
    "# We load the model, and set it to use only one environment\n",
    "model, stat = Exp.load(42, n_envs=1)\n",
    "print(stat)\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449de657df003a77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:16:28.611407354Z",
     "start_time": "2023-09-06T10:16:28.279244658Z"
    }
   },
   "outputs": [],
   "source": [
    "model, stat = Exp.load(42, n_envs=1)\n",
    "\n",
    "# Set the weight decay to 0\n",
    "for module in model.policy.modules():\n",
    "    if isinstance(module, M.WeightDecay):\n",
    "        module.weight_decay = 0\n",
    "        \n",
    "# Turn off gradient for the weights\n",
    "for param in model.policy.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "env = Exp().get_eval_env()\n",
    "dummy_obs = env.reset()[0]\n",
    "\n",
    "# -- Add the mask -- #\n",
    "\n",
    "target_type = torch.nn.Conv2d\n",
    "nth_target = 0\n",
    "after = False\n",
    "\n",
    "# Find the target and the sequential in which it is\n",
    "pre_mask = [m for m in model.policy.modules() if isinstance(m, target_type)][nth_target]\n",
    "sequential = next(m for m in model.policy.modules() if isinstance(m, torch.nn.Sequential) and pre_mask in m)\n",
    "\n",
    "# Find the index of the layer we want to insert the mask after\n",
    "target_idx = next(i for i, m in enumerate(sequential) if m is pre_mask)\n",
    "print(sequential)\n",
    "print(\"Target index:\", target_idx)\n",
    "\n",
    "mask = M.LazyMask()\n",
    "sequential.insert(target_idx + after, M.ZeroOneRegularisation(mask, 0))\n",
    "model.predict(dummy_obs)\n",
    "print(sequential)\n",
    "\n",
    "# Testing that only the mask is trainable\n",
    "trainable = [param for param in model.policy.parameters() if param.requires_grad]\n",
    "assert trainable == [mask.mask], trainable\n",
    "assert len([module for module in model.policy.modules() if isinstance(module, M.Mask)]) == 1, \"Multiple masks, reload the model.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb67b3eca2df56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:18:58.168698324Z",
     "start_time": "2023-09-06T10:18:58.000488505Z"
    }
   },
   "outputs": [],
   "source": [
    "def reward_fn(env: M.ThreeGoalsEnv) -> float:\n",
    "    if mask.flipped:\n",
    "        return env.agent_pos == env.goal_positions[0]  # red\n",
    "    else:\n",
    "        return env.agent_pos == env.goal_positions[1]  # green\n",
    "    \n",
    "mk_env = lambda: M.FunctionRewardWrapper(Exp().get_eval_env(), reward_fn)\n",
    "# mk_env = lambda: Exp().get_train_env()\n",
    "# mk_env = lambda: Exp().get_eval_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac93b074b4427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:21:20.882356744Z",
     "start_time": "2023-09-06T10:21:03.402761578Z"
    }
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Train the model\n",
    "use_wandb = False\n",
    "weight_decay = 0\n",
    "learning_rate = 3e-4\n",
    "model.lr_schedule = lambda _: learning_rate\n",
    "model.verbose = 1\n",
    "model.set_env(mk_env())\n",
    "mask.flipped = 0\n",
    "\n",
    "model.policy.optimizer = torch.optim.AdamW(mask.parameters(), learning_rate, weight_decay=0)\n",
    "# model.batch_size = 100\n",
    "# model.n_steps = 100\n",
    "# model.rollout_buffer.buffer_size = model.n_steps\n",
    "# model.rollout_buffer.reset()\n",
    "\n",
    "class FlipMaskCallback(BaseCallback):\n",
    "    def __init__(self, mask: M.Mask):\n",
    "        super().__init__()\n",
    "        self.mask = mask\n",
    "        \n",
    "    def _on_rollout_start(self) -> None:\n",
    "        self.mask.flip()\n",
    "        print(f\"Flipped mask to {self.mask.flipped}\")\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        return True\n",
    "\n",
    "callbacks = [M.ProgressBarCallback(),\n",
    "             # FlipMaskCallback(mask),\n",
    "             M.WeightDecayCallback(lambda f: weight_decay),\n",
    "             # M.LogChannelNormsCallback()\n",
    "             ]\n",
    "# if use_wandb:\n",
    "#     callbacks.append(M.WandbWithBehaviorCallback(mk_env()))\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=20_000, callback=callbacks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea97a0013019690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:26:49.806016260Z",
     "start_time": "2023-09-06T10:26:49.487071075Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mask.mask[:] = 1\n",
    "    mask.mask[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ab4f1a4327bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:27:21.780360507Z",
     "start_time": "2023-09-06T10:27:21.411019076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the mask\n",
    "px.imshow(mask.mask.detach(), title=\"Mask of the first convolutional layer\", facet_col=0, width=1000, zmin=0, zmax=1, color_continuous_scale=\"Blues\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461edaa1d6ce0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:27:48.695814367Z",
     "start_time": "2023-09-06T10:27:22.664856106Z"
    }
   },
   "outputs": [],
   "source": [
    "M.make_stats(model, mk_env(), 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a9d6a57eaed1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:13:47.502869195Z",
     "start_time": "2023-09-06T10:13:37.370507086Z"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    M.make_stats(model, mk_env(), 1_000)\n",
    "    mask.flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e098e1fa27dc9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T15:23:48.877838077Z",
     "start_time": "2023-09-05T15:23:47.682921955Z"
    }
   },
   "outputs": [],
   "source": [
    "model, _ = Exp.load(42, n_envs=1)\n",
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef0ccba222e4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T15:48:46.888981405Z",
     "start_time": "2023-09-05T15:43:20.610294079Z"
    }
   },
   "outputs": [],
   "source": [
    "with M.record_activations(model.policy) as cache:\n",
    "    agent_pos, goal_pos, end_type, true_goal = M.destination_stats(model, Exp().get_eval_env(), 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1b5d6f6af615e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T15:59:17.513980992Z",
     "start_time": "2023-09-05T15:59:17.404040449Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cache)\n",
    "print(\"Agent pos shape:\", agent_pos.shape)\n",
    "print(\"Goals pos shape:\", goal_pos.shape)\n",
    "print(\"End type shape:\", end_type.shape)\n",
    "print(\"True goal shape:\", true_goal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29804501acac1175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:08:03.778418595Z",
     "start_time": "2023-09-06T10:08:03.291873342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find which activation correspond to which end type\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "end_red_or_green = end_type < 2\n",
    "for name in cache:\n",
    "    print(name)\n",
    "    out = M.show_fit(\n",
    "        # make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        cache[name][end_red_or_green].flatten(1),\n",
    "        end_type[end_red_or_green].bool(),\n",
    "        title=f\"Predicting the end type from the activations of {name}\",\n",
    "        xaxis=\"Predicted end_type is green\",\n",
    "        yaxis=\"True end_type is green\",\n",
    "        classification=True,\n",
    "    )\n",
    "    if \"NOP\" in name:\n",
    "        reg = out\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445c6f027a96325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T10:08:13.820255718Z",
     "start_time": "2023-09-06T10:08:13.658069566Z"
    }
   },
   "outputs": [],
   "source": [
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "\n",
    "# Plot reg.coef_[:-3] as a 5x4x4 image\n",
    "coef = reg.coef_[0, :-3].reshape(-1, 4, 4)\n",
    "px.imshow(coef, facet_col=0, **ZERO_CENTERED, ).show()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c9b3f7464bb48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exploring reward hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c82c775f107d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M.MLP(1, 10, 10, 10, 1, activation=nn.ReLU)\n",
    "\n",
    "lr = 0.2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.00)\n",
    "epochs = 10_000\n",
    "\n",
    "losses = []\n",
    "prediction = []\n",
    "\n",
    "correct = lambda x: np.sin(x / 200 * np.pi * x ** 0.2)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(torch.ones(1))\n",
    "    loss = (out - correct(epoch)) ** 2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    prediction.append(out.item())\n",
    "    \n",
    "# Show prediction and correct on one plot\n",
    "import plotly.graph_objects as go\n",
    "corrects = np.array([correct(i) for i in range(epochs)])\n",
    "predictions = np.array(prediction)\n",
    "losses = np.array(losses)\n",
    "\n",
    "# Clip them\n",
    "predictions = np.clip(predictions, -1, 1)\n",
    "losses = np.clip(losses, 0, 1)\n",
    "\n",
    "skip = 0\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(y=corrects[skip:], name=\"Correct\")\n",
    "fig.add_scatter(y=prediction[skip:], name=\"Prediction\")\n",
    "fig.show()\n",
    "\n",
    "# Show the loss (log scale)\n",
    "px.scatter(y=losses[skip:], log_y=True, title=\"Loss\", labels=dict(y=\"Loss\")).show()\n",
    "px.scatter(y=(corrects - prediction)[skip:], \n",
    "        title=\"Error\", labels=dict(y=\"Error\")).show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
