{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69677c152f22a9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:44:08.312743159Z",
     "start_time": "2023-08-08T10:44:08.274023958Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T11:01:31.786863782Z",
     "start_time": "2023-08-08T11:01:31.582384465Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import einops\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "import plotly.express as px\n",
    "\n",
    "import main as M\n",
    "import three_goals as tg\n",
    "\n",
    "BIG = dict(width=1600, height=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b443ae4baaa9ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:27:16.334718372Z",
     "start_time": "2023-08-08T15:27:16.301449487Z"
    }
   },
   "outputs": [],
   "source": [
    "red, green, blue = tg.ThreeGoalsEnv.GOAL_CELLS\n",
    "env = lambda: (\n",
    "    tg.ColorBlindWrapper.merged(\n",
    "        tg.AddTrueGoalWrapper(\n",
    "            tg.ThreeGoalsEnv(4, true_goal=None)\n",
    "        ),\n",
    "        red, green\n",
    "    )\n",
    ")\n",
    "check_env(env())\n",
    "print(env())\n",
    "print(env().observation_space)\n",
    "print(env().action_space)\n",
    "o, _ = env().reset()\n",
    "switch = o['switch']\n",
    "print(f\"{switch=}\")\n",
    "obs = o['obs']\n",
    "print(obs.astype(int).reshape(4, 4, -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ebbd187325119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:46:36.817267836Z",
     "start_time": "2023-08-08T10:46:36.756011311Z"
    }
   },
   "outputs": [],
   "source": [
    "net = tg.SwitchMLP(4, (64, 64), 2, 3, 0)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc878272530059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:46:38.338360914Z",
     "start_time": "2023-08-08T10:46:38.257376350Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [1.0, 2, 3, 4],\n",
    "    [4.0, 3, 2, 1],\n",
    "])\n",
    "switch_idx = [0, 2]\n",
    "switch = torch.zeros((2, 3))\n",
    "switch[range(2), switch_idx] = 1\n",
    "\n",
    "print(x)\n",
    "print(switch)\n",
    "print(net(x, switch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da550833cda11690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T10:46:40.373987516Z",
     "start_time": "2023-08-08T10:46:40.314999602Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique(x, *, __previous=set()):\n",
    "    \"\"\"Return the argument, if it was never seen before, otherwise raise ValueError\"\"\"\n",
    "    if x in __previous:\n",
    "        raise ValueError(f\"Duplicate value {x}\")\n",
    "    __previous.add(x)\n",
    "    return x\n",
    "\n",
    "class WandbWithBehaviorCallback(WandbCallback):\n",
    "    def __init__(self, show_every=10, **kwargs):\n",
    "        self.show_every = show_every\n",
    "        self.time = 0\n",
    "        super().__init__(**kwargs)\n",
    "    def _on_rollout_start(self) -> None:\n",
    "        super()._on_rollout_start()\n",
    "        # Show every  10 episodes\n",
    "        self.time += 1\n",
    "        if self.time % self.show_every == 0:\n",
    "            M.show_behavior(self.model, env(), max_len=20, add_to_wandb=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466be5caadc1e54",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-08T15:50:18.474994134Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "env_size = 4\n",
    "red, green, blue = tg.ThreeGoalsEnv.GOAL_CELLS\n",
    "env = lambda: (\n",
    "    tg.ColorBlindWrapper.merged(\n",
    "        tg.AddTrueGoalWrapper(\n",
    "            tg.ThreeGoalsEnv(env_size)\n",
    "        ),\n",
    "        red, green\n",
    "    )\n",
    ")\n",
    "# env = lambda: (\n",
    "#     tg.AddTrueGoalWrapper(\n",
    "#         M.FlatOneHotWrapper(tg.ThreeGoalsEnv(None, env_size))\n",
    "#     )\n",
    "# )\n",
    "n_env = 32\n",
    "lr_start, lr_end = 5e-3, 2e-5\n",
    "policy = PPO(\n",
    "    # \"MlpPolicy\",\n",
    "    tg.SwitchActorCriticPolicy,\n",
    "    make_vec_env(env, n_envs=n_env, seed=42),\n",
    "    policy_kwargs=dict(\n",
    "        arch_kwargs=dict(\n",
    "            switched_layer=0,\n",
    "            hidden=[32, 32],\n",
    "            out_dim=4,\n",
    "            n_switches=2,\n",
    "            l1_reg=1e-5,\n",
    "        ),\n",
    "    ),\n",
    "    verbose=2,\n",
    "    # n_epochs=40,\n",
    "    n_steps=2_048 // n_env,\n",
    "    # batch_size=400,\n",
    "    # learning_rate=lambda f: lr_start * f ** 2 + lr_end * (1 - f ** 2),\n",
    "    # policy_kwargs=policy_kwargs,  # optimizer_kwargs=dict(weight_decay=weight_decay)),\n",
    "    # arch_kwargs=dict(net_arch=net_arch, features_extractor_class=BaseFeaturesExtractor),\n",
    "    tensorboard_log=\"run_logs\",\n",
    "    # device='cuda:1'\n",
    ")\n",
    "print(policy.policy)\n",
    "\n",
    "wandb.init(\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    save_code=True,\n",
    "    config=dict(\n",
    "        env_size=env_size,\n",
    "        lr_start=lr_start,\n",
    "        lr_end=lr_end,\n",
    "        arch=policy.policy_kwargs['arch_kwargs']\n",
    "    ),\n",
    "    project=\"switched-3goals-blind\",\n",
    "    notes=unique(\"\"\"\n",
    "Colorblind agent Rewards: true goal=1, wrong goal=0, nothing=-1 at the end of the trajectory\n",
    "Arch 32,32, with regularisation L1=1e-6\n",
    "Regularisation bumped to 1e-5, it wasn't enough\n",
    "Lowered batch size to the default (400 -> 64)\n",
    "Lowered epochs to the default (40 -> 10)\n",
    "Lowered n_steps (8000 -> 2000)\n",
    "Blind BOTH the red-green and blue agents\n",
    "(fixed bug Ã— 2)\n",
    "Changed rewards: true goal=1, wrong goal=0, step=-1/16 (16=board size)\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "policy.learn(total_timesteps=600_000, callback=WandbWithBehaviorCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5a0f6d83e0a64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:39:50.880108895Z",
     "start_time": "2023-08-08T15:39:03.531029120Z"
    }
   },
   "outputs": [],
   "source": [
    "policy.lr_schedule = lambda _: 1e-5\n",
    "policy.learn(total_timesteps=100_000, reset_num_timesteps=False, callback=WandbWithBehaviorCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c422eb1efa3487",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T11:34:36.741643094Z",
     "start_time": "2023-08-08T11:34:36.356873877Z"
    }
   },
   "outputs": [],
   "source": [
    "# M.show_behavior(policy, env(), width=1600, height=1600, max_len=20\n",
    "                # add_to_wandb=True,\n",
    "                # )\n",
    "    \n",
    "wrappers = [\n",
    "    tg.AddTrueGoalWrapper,\n",
    "    lambda e: tg.ColorBlindWrapper.merged(e, [red, green], [blue], disabled=False),\n",
    "]\n",
    "M.show_behavior(policy, tg.ThreeGoalsEnv.interesting(4, 10, wrappers), **BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73867436b9ea6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:42:20.586626160Z",
     "start_time": "2023-08-08T15:42:19.797097195Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_wrappers(e, disabled):\n",
    "    e = tg.AddTrueGoalWrapper(e)\n",
    "    e = tg.ColorBlindWrapper.merged(\n",
    "        e,\n",
    "        red, green,\n",
    "        disabled=disabled)\n",
    "    return e\n",
    "\n",
    "envs = []\n",
    "for i in range(6):\n",
    "    base_env = tg.ThreeGoalsEnv.constant(env_size, true_goal={\"red\": 1, \"green\": 1})\n",
    "    env_blind = add_wrappers(base_env, disabled=False)\n",
    "    env_color = add_wrappers(base_env, disabled=True)\n",
    "    envs.append(env_blind)\n",
    "    envs.append(env_color)\n",
    "        \n",
    "M.show_behavior(policy, envs, **BIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257d5ad74724bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:17:31.804906664Z",
     "start_time": "2023-08-08T15:17:31.736321902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print all models\n",
    "models_dir = Path(\"models\")\n",
    "for model_path in sorted(models_dir.glob(\"*.zip\")):\n",
    "    print(model_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbadfeb4c036e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T12:56:09.839812499Z",
     "start_time": "2023-08-08T12:56:09.536100895Z"
    }
   },
   "outputs": [],
   "source": [
    "name = \"switched-blind=rg-4x4-switch=first-L1=1e-5\"\n",
    "path = models_dir / f\"{name}.zip\"\n",
    "if path.exists():\n",
    "    print(\"Loading existing model\")\n",
    "    previous_policy = policy  # Saved, in case I wanted to save it, but forgot to change the name\n",
    "    policy = PPO.load(path)\n",
    "else:\n",
    "    print(f\"Saving model to {path}\")\n",
    "    policy.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae57831fa740ad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4133102ea0ef53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:42:58.088602457Z",
     "start_time": "2023-08-08T15:42:57.782995857Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(x, **kwargs):\n",
    "    h, w = x.shape[-2:]\n",
    "    if 'facet_col' in kwargs:\n",
    "        wrap = kwargs.get('facet_col_wrap', 1)\n",
    "        h *= np.ceil(x.shape[kwargs['facet_col']] / wrap)\n",
    "        w *= wrap\n",
    "    width = 50 + w * 25\n",
    "    height = h * 25 + 50 * ('title' in kwargs)\n",
    "    while width < 500 and height < 500:\n",
    "        width *= 2\n",
    "        height *= 2\n",
    "    new = dict(\n",
    "        width=max(300, width),\n",
    "        height=max(300, height),\n",
    "        facet_row_spacing=0.01,\n",
    "        facet_col_spacing=0.01,\n",
    "    )\n",
    "    kwargs = {**new, **kwargs}\n",
    "    px.imshow(x, **kwargs).show()\n",
    "\n",
    "\n",
    "switch_biases = policy.policy.mlp_extractor.switch_biases\n",
    "print(\"Biases shape:\", switch_biases.shape)\n",
    "print(\"Max abs bias:\", switch_biases.abs().max(dim=-1).values)\n",
    "imshow(switch_biases, title='Biases of the switch layers', color_continuous_scale='RdBu', color_continuous_midpoint=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f1569b1d07b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:43:00.446070696Z",
     "start_time": "2023-08-08T15:43:00.035657606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the three switch layers\n",
    "\n",
    "switch_layers_weights = policy.policy.mlp_extractor.switch_weights\n",
    "\n",
    "# shape of a switch (out_dim, row, col, obj_type)\n",
    "w1 = einops.rearrange(switch_layers_weights, 'agent out_dim (row col obj_type) -> agent obj_type out_dim row col', row=4, col=4)\n",
    "b1 = einops.repeat(policy.policy.mlp_extractor.switch_biases, 'agent out_dim -> agent 1 out_dim 4 1')\n",
    "\n",
    "avg = w1.mean(dim=0)\n",
    "TYPES = ['empty', 'agent', 'goal_red', 'goal_green', 'goal_blue']\n",
    "EMPTY, AGENT, RED, GREEN, BLUE = range(5)\n",
    "\n",
    "print(w1.shape, avg.shape)\n",
    "# d = w1[:, EMPTY] - avg[EMPTY] \n",
    "d = avg\n",
    "\n",
    "d = w1\n",
    "print(d.shape)\n",
    "# Add one black col\n",
    "d = torch.cat([d, torch.zeros(*d.shape[:-1], 1) + float('nan')], dim=-1)\n",
    "d = torch.cat([d, torch.zeros(*d.shape[:-2], 1, d.shape[-1]) + float('nan')], dim=-2)\n",
    "d = einops.rearrange(d, 'agent obj out row col -> out (agent row) (obj col)')[..., :-1, :]\n",
    "b1 = torch.cat([b1, torch.zeros(*b1.shape[:-2], 1, b1.shape[-1]) + float('nan')], dim=-2)\n",
    "b1 = einops.rearrange(b1, 'agent obj out row col -> out (agent row) (obj col)')[..., :-1, :]\n",
    "print(d.shape, b1.shape)\n",
    "d = torch.cat([d, b1], dim=-1)\n",
    "# Remove weights close to zero\n",
    "# d[abs(d) < 0.1] = float('nan')\n",
    "imshow(d, title='First layer weights', facet_col=0, facet_col_wrap=4,\n",
    "          # height=4000,\n",
    "          # width=None,\n",
    "          color_continuous_scale='RdBu',\n",
    "          color_continuous_midpoint=0,\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451389ecd3d25bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T15:46:58.007888296Z",
     "start_time": "2023-08-08T15:46:57.570904378Z"
    }
   },
   "outputs": [],
   "source": [
    "imshow(w1.flatten(2).mean(dim=2),\n",
    "          title=\"Mean of the weights of the switch layers\",\n",
    "          labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "          )\n",
    "imshow(w1.flatten(2).abs().mean(dim=2), \n",
    "          title=\"Mean absolute value of the weights of the switch layers\",\n",
    "          labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "          )\n",
    "imshow(w1.flatten(2).std(dim=2),\n",
    "            title=\"Std of the weights of the switch layers\",\n",
    "            labels=dict(x=\"Object type\", y=\"Agent\"),\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675396154733477f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T11:44:28.910581511Z",
     "start_time": "2023-08-08T11:44:28.656391461Z"
    }
   },
   "outputs": [],
   "source": [
    "last_layer: torch.nn.Linear = policy.policy.action_net\n",
    "last_weights = last_layer.weight.detach().cpu().clone()\n",
    "last_bias = last_layer.bias.detach().cpu().clone()\n",
    "\n",
    "weights = torch.cat([\n",
    "    last_weights.T @ net.switches[i].weight.detach().cpu().clone()\n",
    "    for i in range(3)\n",
    "], dim=0)\n",
    "imshow(weights)\n",
    "\n",
    "biases = torch.stack([net.switches[i].bias.detach().cpu() for i in range(3)], dim=1)\n",
    "imshow(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b34be96b254156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T11:45:42.581544321Z",
     "start_time": "2023-08-08T11:45:42.181393074Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute correlations between rows of w2\n",
    "w2 = net.post_switch[1].weight.detach().cpu().clone()  # (64, 64)\n",
    "imshow(w2)\n",
    "w2 = w2 / w2.norm(dim=1, keepdim=True)\n",
    "corr = w2 @ w2.T\n",
    "\n",
    "# Cluster the correlations matrix\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial.distance as ssd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Compute and plot first dendrogram.\n",
    "fig = ff.create_dendrogram(\n",
    "    corr.numpy(),\n",
    "    orientation='left',\n",
    "    labels=list(range(64)),\n",
    "    linkagefun=lambda x: sch.linkage(x, 'single'),\n",
    "    distfun=lambda x: ssd.pdist(x, 'euclidean'),\n",
    ")\n",
    "fig.update_layout(width=1000, height=1000)\n",
    "fig.show()\n",
    "\n",
    "# Remove the diagonal\n",
    "corr[range(64), range(64)] = float('nan')\n",
    "px.imshow(corr, width=1000, height=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
